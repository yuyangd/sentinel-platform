apiVersion: ray.io/v1
kind: RayService
metadata:
  name: sentinel-serving-factcheck
  namespace: sentinel-prod
spec:
  # 0. Define a classic load balancer to route traffic
  serveService:
      metadata:
        name: sentinel-service-serve-svc # Explicitly naming it helps debugging
        annotations:
          service.beta.kubernetes.io/aws-load-balancer-type: "nlb"
          service.beta.kubernetes.io/aws-load-balancer-additional-resource-tags: "Owner=du.y,Project=training,rea-system-id=x-du-yuyang"
      spec:
        type: LoadBalancer
        ports:
        - port: 8000
          targetPort: 8000
          name: serve
  # 1. Define the Serve Config (The Application)
  serveConfigV2: |
    applications:
      - name: sentinel
        # Import path must match your code structure inside the container.
        # Dockerfile puts code in /app/serve/main.py and PYTHONPATH includes /app.
        import_path: serve.facecheck:deployment
        route_prefix: /
        runtime_env:
          pip:
            - transformers
        deployments:
          - name: FactCheckGuardrail
            autoscaling_config:
              min_replicas: 1
              max_replicas: 5
              target_num_ongoing_requests_per_replica: 5 # Aggressive! Scales up if >5 concurrent requests.
              upscale_delay_s: 1 # Scale up FAST for demos
              downscale_delay_s: 30 # Scale down slower
            ray_actor_options:
              num_cpus: 0.5
  # 2. Define the Cluster Config (The Infrastructure)
  rayClusterConfig:
    rayVersion: '2.53.0'
    headGroupSpec:
      rayStartParams:
        dashboard-host: '0.0.0.0'
      template:
        spec:
          containers:
          - name: ray-head
            image: duyuyang545/sentinel-serve:v1
            imagePullPolicy: IfNotPresent
            ports:
            - containerPort: 8265
              name: dashboard
            - containerPort: 8000
              name: serve
            resources:
              limits:
                cpu: "1"
                memory: "4Gi"
              requests:
                cpu: "1"
                memory: "4Gi"
    workerGroupSpecs:
    - replicas: 1
      minReplicas: 1
      maxReplicas: 1
      groupName: worker-group
      rayStartParams: {}
      template:
        spec:
          nodeSelector:
            intention: training
            lifecycle: Ec2Spot
          containers:
          - name: ray-worker
            # Workers also need the custom image to run the replicas
            image: duyuyang545/sentinel-serve:v1
            imagePullPolicy: Always
            resources:
              limits:
                cpu: "1"
                memory: "2Gi"
              requests:
                cpu: "1"
                memory: "2Gi"
